│                    │                     │          │                         │                  │ https://avd.aquasec.com/nvd/cve-2023-50495                   │
├────────────────────┤                     │          │                         ├──────────────────┤                                                              │
│ ncurses-bin        │                     │          │                         │                  │                                                              │
│                    │                     │          │                         │                  │                                                              │
├────────────────────┼─────────────────────┤          ├─────────────────────────┼──────────────────┼──────────────────────────────────────────────────────────────┤
│ openssl            │ CVE-2024-13176      │          │ 3.0.15-1~deb12u1        │                  │ openssl: Timing side-channel in ECDSA signature computation  │
│                    │                     │          │                         │                  │ https://avd.aquasec.com/nvd/cve-2024-13176                   │
├────────────────────┼─────────────────────┤          ├─────────────────────────┼──────────────────┼──────────────────────────────────────────────────────────────┤
│ passwd             │ CVE-2023-4641       │          │ 1:4.13+dfsg1-1          │                  │ shadow-utils: possible password leak during passwd(1) change │
│                    │                     │          │                         │                  │ https://avd.aquasec.com/nvd/cve-2023-4641                    │
│                    ├─────────────────────┼──────────┤                         ├──────────────────┼──────────────────────────────────────────────────────────────┤
│                    │ CVE-2007-5686       │ LOW      │                         │                  │ initscripts in rPath Linux 1 sets insecure permissions for   │
│                    │                     │          │                         │                  │ the /var/lo ......                                           │
│                    │                     │          │                         │                  │ https://avd.aquasec.com/nvd/cve-2007-5686                    │
│                    ├─────────────────────┤          │                         ├──────────────────┼──────────────────────────────────────────────────────────────┤
│                    │ CVE-2023-29383      │          │                         │                  │ shadow: Improper input validation in shadow-utils package    │
│                    │                     │          │                         │                  │ utility chfn                                                 │
│                    │                     │          │                         │                  │ https://avd.aquasec.com/nvd/cve-2023-29383                   │
│                    ├─────────────────────┤          │                         ├──────────────────┼──────────────────────────────────────────────────────────────┤
│                    │ CVE-2024-56433      │          │                         │                  │ shadow-utils: Default subordinate ID configuration in        │
│                    │                     │          │                         │                  │ /etc/login.defs could lead to compromise                     │
│                    │                     │          │                         │                  │ https://avd.aquasec.com/nvd/cve-2024-56433                   │
│                    ├─────────────────────┤          │                         ├──────────────────┼──────────────────────────────────────────────────────────────┤
│                    │ TEMP-0628843-DBAD28 │          │                         │                  │ [more related to CVE-2005-4890]                              │
│                    │                     │          │                         │                  │ https://security-tracker.debian.org/tracker/TEMP-0628843-DB- │
│                    │                     │          │                         │                  │ AD28                                                         │
├────────────────────┼─────────────────────┼──────────┼─────────────────────────┼──────────────────┼──────────────────────────────────────────────────────────────┤
│ perl-base          │ CVE-2023-31484      │ HIGH     │ 5.36.0-7+deb12u1        │                  │ perl: CPAN.pm does not verify TLS certificates when          │
│                    │                     │          │                         │                  │ downloading distributions over HTTPS...                      │
│                    │                     │          │                         │                  │ https://avd.aquasec.com/nvd/cve-2023-31484                   │
│                    ├─────────────────────┼──────────┤                         ├──────────────────┼──────────────────────────────────────────────────────────────┤
│                    │ CVE-2011-4116       │ LOW      │                         │                  │ perl: File:: Temp insecure temporary file handling           │
│                    │                     │          │                         │                  │ https://avd.aquasec.com/nvd/cve-2011-4116                    │
│                    ├─────────────────────┤          │                         ├──────────────────┼──────────────────────────────────────────────────────────────┤
│                    │ CVE-2023-31486      │          │                         │                  │ http-tiny: insecure TLS cert default                         │
│                    │                     │          │                         │                  │ https://avd.aquasec.com/nvd/cve-2023-31486                   │
├────────────────────┼─────────────────────┤          ├─────────────────────────┼──────────────────┼──────────────────────────────────────────────────────────────┤
│ sysvinit-utils     │ TEMP-0517018-A83CE6 │          │ 3.06-4                  │                  │ [sysvinit: no-root option in expert installer exposes        │
│                    │                     │          │                         │                  │ locally exploitable security flaw]                           │
│                    │                     │          │                         │                  │ https://security-tracker.debian.org/tracker/TEMP-0517018-A8- │
│                    │                     │          │                         │                  │ 3CE6                                                         │
├────────────────────┼─────────────────────┤          ├─────────────────────────┼──────────────────┼──────────────────────────────────────────────────────────────┤
│ tar                │ CVE-2005-2541       │          │ 1.34+dfsg-1.2+deb12u1   │                  │ tar: does not properly warn the user when extracting setuid  │
│                    │                     │          │                         │                  │ or setgid...                                                 │
│                    │                     │          │                         │                  │ https://avd.aquasec.com/nvd/cve-2005-2541                    │
│                    ├─────────────────────┤          │                         ├──────────────────┼──────────────────────────────────────────────────────────────┤
│                    │ TEMP-0290435-0B57B5 │          │                         │                  │ [tar's rmt command may have undesired side effects]          │
│                    │                     │          │                         │                  │ https://security-tracker.debian.org/tracker/TEMP-0290435-0B- │
│                    │                     │          │                         │                  │ 57B5                                                         │
├────────────────────┼─────────────────────┤          ├─────────────────────────┼──────────────────┼──────────────────────────────────────────────────────────────┤
│ util-linux         │ CVE-2022-0563       │          │ 2.38.1-5+deb12u3        │                  │ util-linux: partial disclosure of arbitrary files in chfn    │
│                    │                     │          │                         │                  │ and chsh when compiled...                                    │
│                    │                     │          │                         │                  │ https://avd.aquasec.com/nvd/cve-2022-0563                    │
├────────────────────┤                     │          │                         ├──────────────────┤                                                              │
│ util-linux-extra   │                     │          │                         │                  │                                                              │
│                    │                     │          │                         │                  │                                                              │
├────────────────────┼─────────────────────┼──────────┼─────────────────────────┼──────────────────┼──────────────────────────────────────────────────────────────┤
│ zlib1g             │ CVE-2023-45853      │ CRITICAL │ 1:1.2.13.dfsg-1         │                  │ zlib: integer overflow and resultant heap-based buffer       │
│                    │                     │          │                         │                  │ overflow in zipOpenNewFileInZip4_6                           │
│                    │                     │          │                         │                  │ https://avd.aquasec.com/nvd/cve-2023-45853                   │
└────────────────────┴─────────────────────┴──────────┴─────────────────────────┴──────────────────┴──────────────────────────────────────────────────────────────┘
[ec2-user@ip-172-31-84-4 booking-project]$
sudo docker run -d   --name=cadvisor   --volume=/:/rootfs:ro   --volume=/var/run:/var/run:ro   --volume=/sys:/sys:ro   --volume=/var/lib/docker/:/var/lib/docker:ro   --publish=8080:8080   --restart=always   google/cadvisor:latest
[ec2-user@ip-172-31-84-4 booking-project]$ sudo docker run -d   --name=cadvisor   --volume=/:/rootfs:ro   --volume=/var/run:/var/run:ro   --volume=/sys:/sys:ro   --volume=/var/lib/docker/:/var/lib/docker:ro   --publish=8080:8080   --restart=always   google/cadvisor:latest
Unable to find image 'google/cadvisor:latest' locally
latest: Pulling from google/cadvisor
ff3a5c916c92: Pull complete
44a45bb65cdf: Pull complete
0bbe1a2fe2a6: Pull complete
Digest: sha256:815386ebbe9a3490f38785ab11bda34ec8dacf4634af77b8912832d4f85dca04
Status: Downloaded newer image for google/cadvisor:latest
e33936c365b7e1a4431251f9af41644b449ebc7d9087faf59b681ca5e6305272
sudo docker ps
[ec2-user@ip-172-31-84-4 booking-project]$ sudo docker ps
CONTAINER ID   IMAGE                     COMMAND                  CREATED         STATUS                           PORTS                               NAMES
e33936c365b7   google/cadvisor:latest    "/usr/bin/cadvisor -…"   9 minutes ago   Restarting (255) 4 seconds ago                                       cadvisor
55ee02a65598   eremark/booking-website   "httpd-foreground"       22 hours ago    Up 56 minutes                    0.0.0.0:80->80/tcp, :::80->80/tcp   booking-project-web-1
sudo docker logs cadvisor
[ec2-user@ip-172-31-84-4 booking-project]$ sudo docker logs cadvisor
F0212 15:23:42.977253       1 cadvisor.go:146] Failed to create a Container Manager: mountpoint for cpu not found
F0212 15:23:43.642636       1 cadvisor.go:146] Failed to create a Container Manager: mountpoint for cpu not found
F0212 15:23:44.217699       1 cadvisor.go:146] Failed to create a Container Manager: mountpoint for cpu not found
F0212 15:23:44.999039       1 cadvisor.go:146] Failed to create a Container Manager: mountpoint for cpu not found
F0212 15:23:46.191616       1 cadvisor.go:146] Failed to create a Container Manager: mountpoint for cpu not found
F0212 15:23:48.167352       1 cadvisor.go:146] Failed to create a Container Manager: mountpoint for cpu not found
F0212 15:23:51.744011       1 cadvisor.go:146] Failed to create a Container Manager: mountpoint for cpu not found
F0212 15:23:58.545437       1 cadvisor.go:146] Failed to create a Container Manager: mountpoint for cpu not found
F0212 15:24:11.761229       1 cadvisor.go:146] Failed to create a Container Manager: mountpoint for cpu not found
F0212 15:24:37.737775       1 cadvisor.go:146] Failed to create a Container Manager: mountpoint for cpu not found
F0212 15:25:29.336486       1 cadvisor.go:146] Failed to create a Container Manager: mountpoint for cpu not found
F0212 15:26:29.807318       1 cadvisor.go:146] Failed to create a Container Manager: mountpoint for cpu not found
F0212 15:27:30.205467       1 cadvisor.go:146] Failed to create a Container Manager: mountpoint for cpu not found
F0212 15:28:30.578307       1 cadvisor.go:146] Failed to create a Container Manager: mountpoint for cpu not found
F0212 15:29:31.076993       1 cadvisor.go:146] Failed to create a Container Manager: mountpoint for cpu not found
F0212 15:30:31.484334       1 cadvisor.go:146] Failed to create a Container Manager: mountpoint for cpu not found
F0212 15:31:31.844533       1 cadvisor.go:146] Failed to create a Container Manager: mountpoint for cpu not found
F0212 15:32:32.330231       1 cadvisor.go:146] Failed to create a Container Manager: mountpoint for cpu not found
F0212 15:33:32.716149       1 cadvisor.go:146] Failed to create a Container Manager: mountpoint for cpu not found
sudo docker run -d   --name=cadvisor   --volume=/:/rootfs:ro   --volume=/var/run:/var/run:ro   --publish=8080:8080   --restart=always   google/cadvisor:latest
sudo docker run -d   --name=cadvisor   --privileged   --volume=/:/rootfs:ro   --volume=/var/run:/var/run:ro   --volume=/sys:/sys:ro   --volume=/var/lib/docker/:/var/lib/docker:ro   --publish=8080:8080   --restart=always   google/cadvisor:latest
[ec2-user@ip-172-31-84-4 booking-project]$ sudo docker run -d   --name=cadvisor   --privileged   --volume=/:/rootfs:ro   --volume=/var/run:/var/run:ro   --volume=/sys:/sys:ro   --volume=/var/lib/docker/:/var/lib/docker:ro   --publish=8080:8080   --restart=always   google/cadvisor:latest
docker: Error response from daemon: Conflict. The container name "/cadvisor" is already in use by container "e33936c365b7e1a4431251f9af41644b449ebc7d9087faf59b681ca5e6305272". You have to remove (or rename) that container to be able to reuse that name.
See 'docker run --help'.
ect]$ sudo docker run -d   --name=cadvisor   --privileged   --volume=/:/rootfs:ro   --volume=/var/run:/var/run:ro   --volume=/sys:/sys:ro   --volume=/var/lib/docker/:/var/lib/docker:ro   --publish=8080:8080   --restart=always   google/cadvisor:latest
docker: Error response from daemon: Conflict. The container name "/cadvisor" is already in use by container "e33936c365b7e1a4431251f9af41644b449ebc7d9087faf59b681ca5e6305272". You have to remove (or rename) that container to be able to reuse that name.
See 'docker run --help'.
-bash: [ec2-user@ip-172-31-84-4: command not found
-bash: syntax error near unexpected token `('
-bash: See: command not found
ect]$ sudo docker run -d \
  --name=cadvisor \
  --privileged \
  --volume=/:/rootfs:ro \
  --volume=/var/run:/var/run:ro \
  --volume=/sys:/sys:ro \
  --volume=/var/lib/docker/:/var/lib/docker:ro \
  --publish=8080:8080 \
  --restart=always \
  google/cadvisor:latest
docker: Error response from daemon: Conflict. The container name "/cadvisor" is already in use by container "e33936c365b7e1a4431251f9af41644b449ebc7d9087faf59b681ca5e6305272". You have to remove (or rename) that container to be able to reuse that name.
See 'docker run --help'.
-bash: [ec2-user@ip-172-31-84-4: command not found
-bash: syntax error near unexpected token `('
-bash: See: command not found
sudo docker stop cadvisor
sudo docker rm cadvisor
sudo docker run -d   --name=cadvisor   --privileged   --volume=/:/rootfs:ro   --volume=/var/run:/var/run:ro   --volume=/sys:/sys:ro   --volume=/var/lib/docker/:/var/lib/docker:ro   --publish=8080:8080   --restart=always   google/cadvisor:latest
[ec2-user@ip-172-31-84-4 booking-project]$ sudo docker run -d   --name=cadvisor   --privileged   --volume=/:/rootfs:ro   --volume=/var/run:/var/run:ro   --volume=/sys:/sys:ro   --volume=/var/lib/docker/:/var/lib/docker:ro   --publish=8080:8080   --restart=always   google/cadvisor:latest
0cbfcd723593be2ce7d9faf7a25f3e8f89ffd83385954a2c2d66092c2a3fd6a0
sudo docker ps
[ec2-user@ip-172-31-84-4 booking-project]$ sudo docker ps
CONTAINER ID   IMAGE                     COMMAND                  CREATED         STATUS                            PORTS                               NAMES
0cbfcd723593   google/cadvisor:latest    "/usr/bin/cadvisor -…"   3 minutes ago   Restarting (255) 11 seconds ago                                       cadvisor
55ee02a65598   eremark/booking-website   "httpd-foreground"       22 hours ago    Up About an hour                  0.0.0.0:80->80/tcp, :::80->80/tcp   booking-project-web-1
sudo docker logs cadvisor
[ec2-user@ip-172-31-84-4 booking-project]$ sudo docker logs cadvisor
F0212 15:40:01.555855       1 cadvisor.go:146] Failed to create a Container Manager: mountpoint for cpu not found
F0212 15:40:02.160441       1 cadvisor.go:146] Failed to create a Container Manager: mountpoint for cpu not found
F0212 15:40:02.749943       1 cadvisor.go:146] Failed to create a Container Manager: mountpoint for cpu not found
F0212 15:40:03.552462       1 cadvisor.go:146] Failed to create a Container Manager: mountpoint for cpu not found
F0212 15:40:04.748255       1 cadvisor.go:146] Failed to create a Container Manager: mountpoint for cpu not found
F0212 15:40:06.759995       1 cadvisor.go:146] Failed to create a Container Manager: mountpoint for cpu not found
F0212 15:40:10.367835       1 cadvisor.go:146] Failed to create a Container Manager: mountpoint for cpu not found
F0212 15:40:17.146969       1 cadvisor.go:146] Failed to create a Container Manager: mountpoint for cpu not found
F0212 15:40:30.336647       1 cadvisor.go:146] Failed to create a Container Manager: mountpoint for cpu not found
F0212 15:40:56.425854       1 cadvisor.go:146] Failed to create a Container Manager: mountpoint for cpu not found
F0212 15:41:48.029578       1 cadvisor.go:146] Failed to create a Container Manager: mountpoint for cpu not found
F0212 15:42:48.400630       1 cadvisor.go:146] Failed to create a Container Manager: mountpoint for cpu not found
[ec2-user@ip-172-31-84-4 booking-project]$ sudo docker logs cadvisor
F0212 15:40:01.555855       1 cadvisor.go:146] Failed to create a Container Manager: mountpoint for cpu not found
F0212 15:40:02.160441       1 cadvisor.go:146] Failed to create a Container Manager: mountpoint for cpu not found
F0212 15:40:02.749943       1 cadvisor.go:146] Failed to create a Container Manager: mountpoint for cpu not found
F0212 15:40:03.552462       1 cadvisor.go:146] Failed to create a Container Manager: mountpoint for cpu not found
F0212 15:40:04.748255       1 cadvisor.go:146] Failed to create a Container Manager: mountpoint for cpu not found
F0212 15:40:06.759995       1 cadvisor.go:146] Failed to create a Container Manager: mountpoint for cpu not found
F0212 15:40:10.367835       1 cadvisor.go:146] Failed to create a Container Manager: mountpoint for cpu not found
F0212 15:40:17.146969       1 cadvisor.go:146] Failed to create a Container Manager: mountpoint for cpu not found
F0212 15:40:30.336647       1 cadvisor.go:146] Failed to create a Container Manager: mountpoint for cpu not found
F0212 15:40:56.425854       1 cadvisor.go:146] Failed to create a Container Manager: mountpoint for cpu not found
F0212 15:41:48.029578       1 cadvisor.go:146] Failed to create a Container Manager: mountpoint for cpu not found
F0212 15:42:48.400630       1 cadvisor.go:146] Failed to create a Container Manager: mountpoint for cpu not found
F0212 15:43:48.780842       1 cadvisor.go:146] Failed to create a Container Manager: mountpoint for cpu not found
ls /sys
ls /var/run
ls /var/lib/docker
[ec2-user@ip-172-31-84-4 booking-project]$ ls /sys
ls /var/run
ls /var/lib/docker
block  class  devices   fs          kernel  power
bus    dev    firmware  hypervis
sudo chmod 755 /var/lib/docker
sudo systemctl status docker
docker ps
sudo docker run -d   --name=cadvisor   --volume=/:/rootfs:ro   --volume=/var/run:/var/run:ro   --volume=/sys:/sys:ro   --publish=8080:8080   --restart=always   google/cadvisor:latest
[ec2-user@ip-172-31-84-4 ~]$ sudo docker run -d   --name=cadvisor   --volume=/:/rootfs:ro   --volume=/var/run:/var/run:ro   --volume=/sys:/sys:ro   --publish=8080:8080   --restart=always   google/cadvisor:latest
docker: Error response from daemon: Conflict. The container name "/cadvisor" is already in use by container "0cbfcd723593be2ce7d9faf7a25f3e8f89ffd83385954a2c2d66092c2a3fd6a0". You have to remove (or rename) that container to be able to reuse that name.
See 'docker run --help'.
sudo docker stop cadvisor
sudo docker rm cadvisor
sudo docker run -d   --name=cadvisor_new   --volume=/:/rootfs:ro   --volume=/var/run:/var/run:ro   --volume=/sys:/sys:ro   --publish=8080:8080   --restart=always   google/cadvisor:latest
sudo docker logs cadvisor
sudo docker ps
[ec2-user@ip-172-31-84-4 ~]$ sudo docker ps
CONTAINER ID   IMAGE                     COMMAND                  CREATED         STATUS                            PORTS                               NAMES
ddb0aac63e7d   google/cadvisor:latest    "/usr/bin/cadvisor -…"   3 minutes ago   Restarting (255) 16 seconds ago                                       cadvisor_new
55ee02a65598   eremark/booking-website   "httpd-foreground"       23 hours ago    Up About an hour                  0.0.0.0:80->80/tcp, :::80->80/tcp   booking-project-web-1
[ec2-user@ip-172-31-84-4 ~]$ sudo docker ps
CONTAINER ID   IMAGE                     COMMAND                  CREATED         STATUS                            PORTS                               NAMES
ddb0aac63e7d   google/cadvisor:latest    "/usr/bin/cadvisor -…"   3 minutes ago   Restarting (255) 16 seconds ago                                       cadvisor_new
55ee02a65598   eremark/booking-website   "httpd-foreground"       23 hours ago    Up About an hour                  0.0.0.0:80->80/tcp, :::80->80/tcp   booking-project-web-1
sudo docker logs cadvisor_new
sudo docker stop cadvisor_new
sudo docker rm cadvisor_new
sudo docker run -d   --name=cadvisor_new   --volume=/:/rootfs:ro   --volume=/var/run:/var/run:ro   --volume=/sys:/sys:ro   --publish=8080:8080   --restart=always   google/cadvisor:latest
sudo netstat -tuln | grep 8080
sudo apt install trivy
 sudo apt install trivy
sudo: apt: command not found
sudo dnf install -y epel-release
sudo dnf install -y trivy
[ec2-user@ip-172-31-84-4 ~]$ sudo dnf install -y epel-release
sudo dnf install -y trivy
Last metadata expiration check: 10:59:08 ago on Wed Feb 12 05:03:03 2025.
No match for argument: epel-release
Error: Unable to find a match: epel-release
Last metadata expiration check: 10:59:09 ago on Wed Feb 12 05:03:03 2025.
Package trivy-0.34.0-1.x86_64 is already installed.
Dependencies resolved.
Nothing to do.
Complete!
trivy --version
[ec2-user@ip-172-31-84-4 ~]$ trivy --version
Version: 0.34.0
Vulnerability DB:
  Version: 2
  UpdatedAt: 2025-02-12 12:17:27.613779762 +0000 UTC
  NextUpdate: 2025-02-13 12:17:27.613779472 +0000 UTC
  DownloadedAt: 2025-02-12 15:19:42.228882884 +0000 UTC
trivy image eremark/booking-website
trivy image $(sudo docker ps --format "{{.Image}}")
trivy fs /home/ec2-user/booking-project
trivy --quiet --format table --scanners vuln,secret,misconfig --severity HIGH,CRITICAL image $(sudo docker ps --format "{{.Image}}")
trivy image $(sudo docker ps --format "{{.Image}}")
[ec2-user@ip-172-31-84-4 ~]$ trivy image $(sudo docker ps --format "{{.Image}}")
Scan a container image
Usage:
  trivy image [flags] IMAGE_NAME
Aliases:
  image, i
Examples:
  # Scan a container image
  $ trivy image python:3.4-alpine
  # Scan a container image from a tar archive
  $ trivy image --input ruby-3.1.tar
  # Filter by severities
  $ trivy image --severity HIGH,CRITICAL alpine:3.15
  # Ignore unfixed/unpatched vulnerabilities
  $ trivy image --ignore-unfixed alpine:3.15
  # Scan a container image in client mode
  $ trivy image --server http://127.0.0.1:4954 alpine:latest
  # Generate json result
  $ trivy image --format json --output result.json alpine:3.15
  # Generate a report in the CycloneDX format
  $ trivy image --format cyclonedx --output result.cdx --security-checks none alpine:3.15
Scan Flags
      --file-patterns strings     specify config file patterns
      --offline-scan              do not issue API requests to identify dependencies
      --rekor-url string          [EXPERIMENTAL] address of rekor STL server (default "https://rekor.sigstore.dev")
      --sbom-sources strings      [EXPERIMENTAL] try to retrieve SBOM from the specified sources (rekor)
      --security-checks strings   comma-separated list of what security issues to detect (vuln,config,secret,license) (default [vuln,secret])
      --skip-dirs strings         specify the directories where the traversal is skipped
      --skip-files strings        specify the file paths to skip traversal
Report Flags
      --compliance string      comma-separated list of what compliance reports to generate (nsa)
      --dependency-tree        [EXPERIMENTAL] show dependency origin tree of vulnerable packages
      --exit-code int          specify exit code when any security issues are found
  -f, --format string          format (table, json, sarif, template, cyclonedx, spdx, spdx-json, github, cosign-vuln) (default "table")
      --ignore-policy string   specify the Rego file path to evaluate each vulnerability
      --ignorefile string      specify .trivyignore file (default ".trivyignore")
      --list-all-pkgs          enabling the option will output all packages regardless of vulnerability
  -o, --output string          output file name
  -s, --severity string        severities of security issues to be displayed (comma separated) (default "UNKNOWN,LOW,MEDIUM,HIGH,CRITICAL")
  -t, --template string        output template
Cache Flags
      --cache-backend string   cache backend (e.g. redis://localhost:6379) (default "fs")
      --cache-ttl duration     cache TTL when using redis as cache backend
      --clear-cache            clear image caches without scanning
      --redis-ca string        redis ca file location, if using redis as cache backend
      --redis-cert string      redis certificate file location, if using redis as cache backend
      --redis-key string       redis key file location, if using redis as cache backend
DB Flags
      --db-repository string   OCI repository to retrieve trivy-db from (default "ghcr.io/aquasecurity/trivy-db")
      --download-db-only       download/update vulnerability database but don't run a scan
      --no-progress            suppress progress bar
      --reset                  remove all caches and database
      --skip-db-update         skip updating vulnerability database

Image Flags
      --input string      input file path instead of image name
      --platform string   set platform in the form os/arch if image is multi-platform capable
      --removed-pkgs      detect vulnerabilities of removed packages (only for Alpine)

Vulnerability Flags
      --ignore-unfixed     display only fixed vulnerabilities
      --vuln-type string   comma-separated list of vulnerability types (os,library) (default "os,library")

Misconfiguration Flags
      --helm-set strings          specify Helm values on the command line (can specify multiple or separate values with commas: key1=val1,key2=val2)
      --helm-set-file strings     specify Helm values from respective files specified via the command line (can specify multiple or separate values with commas: key1=path1,key2=path2)
      --helm-set-string strings   specify Helm string values on the command line (can specify multiple or separate values with commas: key1=val1,key2=val2)
      --helm-values strings       specify paths to override the Helm values.yaml files
      --include-non-failures      include successes and exceptions, available with '--security-checks config'
      --tf-vars strings           specify paths to override the Terraform tfvars files

Secret Flags
      --secret-config string   specify a path to config file for secret scanning (default "trivy-secret.yaml")

License Flags
      --ignored-licenses strings   specify a list of license to ignore
      --license-full               eagerly look for licenses in source code headers and license files

Rego Flags
      --config-data strings         specify paths from which data for the Rego policies will be recursively loaded
      --config-policy strings       specify paths to the Rego policy files directory, applying config files
      --policy-namespaces strings   Rego namespaces
      --trace                       enable more verbose trace output for custom queries

Client/Server Flags
      --custom-headers strings   custom headers in client mode
      --server string            server address in client mode
      --token string             for authentication in client/server mode
      --token-header string      specify a header name for token in client/server mode (default "Trivy-Token")

Global Flags:
      --cache-dir string          cache directory (default "/home/ec2-user/.cache/trivy")
  -c, --config string             config path (default "trivy.yaml")
  -d, --debug                     debug mode
      --generate-default-config   write the default config to trivy-default.yaml
      --insecure                  allow insecure server connections when using TLS
  -q, --quiet                     suppress progress bar and log output
      --timeout duration          timeout (default 5m0s)
  -v, --version                   show version
2025-02-12T18:20:13.321Z        FATAL   multiple targets cannot be specified
[ec2-user@ip-172-31-84-4 ~]$

sudo docker ps --format "{{.Image}}" | while read image; do trivy image "$image"; done
trivy image eremark/booking-website
sudo docker ps --format "{{.Image}}" | while read image; do trivy image --severity HIGH,CRITICAL "$image"; done
[ec2-user@ip-172-31-84-4 ~]$ sudo docker ps --format "{{.Image}}" | while read image; do trivy image --severity HIGH,CRITICAL "$image"; done
2025-02-12T18:26:25.706Z        INFO    Vulnerability scanning is enabled
2025-02-12T18:26:25.706Z        INFO    Secret scanning is enabled
2025-02-12T18:26:25.706Z        INFO    If your scanning is slow, please try '--security-checks vuln' to disable secret scanning
2025-02-12T18:26:25.706Z        INFO    Please see also https://aquasecurity.github.io/trivy/v0.34/docs/secret/scanning/#recommendation for faster secret detection
2025-02-12T18:26:25.717Z        INFO    Detected OS: alpine
2025-02-12T18:26:25.717Z        INFO    Detecting Alpine vulnerabilities...
2025-02-12T18:26:25.717Z        INFO    Number of language-specific files: 0
2025-02-12T18:26:25.718Z        WARN    This OS version is no longer supported by the distribution: alpine 3.7.0
2025-02-12T18:26:25.718Z        WARN    The vulnerability detection may be insufficient because security updates are not provided
google/cadvisor:latest (alpine 3.7.0)
Total: 7 (HIGH: 5, CRITICAL: 2)
┌───────────────────────┬────────────────┬──────────┬───────────────────┬───────────────┬─────────────────────────────────────────────────────────────┐
│        Library        │ Vulnerability  │ Severity │ Installed Version │ Fixed Version │                            Title                            │
├───────────────────────┼────────────────┼──────────┼───────────────────┼───────────────┼─────────────────────────────────────────────────────────────┤
│ expat                 │ CVE-2018-20843 │ HIGH     │ 2.2.5-r0          │ 2.2.7-r0      │ expat: large number of colons in input makes parser consume │
│                       │                │          │                   │               │ high amount...                                              │
│                       │                │          │                   │               │ https://avd.aquasec.com/nvd/cve-2018-20843                  │
│                       ├────────────────┤          │                   ├───────────────┼─────────────────────────────────────────────────────────────┤
│                       │ CVE-2019-15903 │          │                   │ 2.2.7-r1      │ expat: heap-based buffer over-read via crafted XML input    │
│                       │                │          │                   │               │ https://avd.aquasec.com/nvd/cve-2019-15903                  │
├───────────────────────┼────────────────┤          ├───────────────────┼───────────────┼─────────────────────────────────────────────────────────────┤
│ libressl2.6-libcrypto │ CVE-2018-0732  │          │ 2.6.3-r0          │ 2.6.5-r0      │ openssl: Malicious server can send large prime to client    │
│                       │                │          │                   │               │ during DH(E) TLS...                                         │
│                       │                │          │                   │               │ https://avd.aquasec.com/nvd/cve-2018-0732                   │
├───────────────────────┤                │          │                   │               │                                                             │
│ libressl2.6-libssl    │                │          │                   │               │                                                             │
│                       │                │          │                   │               │                                                             │
├───────────────────────┼────────────────┼──────────┼───────────────────┼───────────────┼─────────────────────────────────────────────────────────────┤
│ musl                  │ CVE-2019-14697 │ CRITICAL │ 1.1.18-r2         │ 1.1.18-r4     │ musl libc through 1.1.23 has an x87 floating-point stack    │
│                       │                │          │                   │               │ adjustment im ......                                        │
│                       │                │          │                   │               │ https://avd.aquasec.com/nvd/cve-2019-14697                  │
├───────────────────────┤                │          │                   │               │                                                             │
│ musl-utils            │                │          │                   │               │                                                             │
│                       │                │          │                   │               │                                                             │
├───────────────────────┼────────────────┼──────────┼───────────────────┼───────────────┼─────────────────────────────────────────────────────────────┤
│ wget                  │ CVE-2018-20483 │ HIGH     │ 1.19.5-r0         │ 1.20.1-r0     │ wget: Information exposure in set_file_metadata function in │
│                       │                │          │                   │               │ xattr.c                                                     │
│                       │                │          │                   │               │ https://avd.aquasec.com/nvd/cve-2018-20483                  │
└───────────────────────┴────────────────┴──────────┴───────────────────┴───────────────┴─────────────────────────────────────────────────────────────┘
2025-02-12T18:26:26.283Z        INFO    Vulnerability scanning is enabled
2025-02-12T18:26:26.283Z        INFO    Secret scanning is enabled
2025-02-12T18:26:26.283Z        INFO    If your scanning is slow, please try '--security-checks vuln' to disable secret scanning
2025-02-12T18:26:26.283Z        INFO    Please see also https://aquasecurity.github.io/trivy/v0.34/docs/secret/scanning/#recommendation for faster secret detection
2025-02-12T18:26:26.292Z        INFO    Detected OS: debian
2025-02-12T18:26:26.292Z        INFO    Detecting Debian vulnerabilities...
2025-02-12T18:26:26.307Z        INFO    Number of language-specific files: 0
eremark/booking-website (debian 12.9)
Total: 11 (HIGH: 10, CRITICAL: 1)
┌──────────────────┬────────────────┬──────────┬─────────────────────────┬───────────────┬─────────────────────────────────────────────────────────────┐
│     Library      │ Vulnerability  │ Severity │    Installed Version    │ Fixed Version │                            Title                            │
├──────────────────┼────────────────┼──────────┼─────────────────────────┼───────────────┼─────────────────────────────────────────────────────────────┤
│ libexpat1        │ CVE-2023-52425 │ HIGH     │ 2.5.0-1+deb12u1         │               │ expat: parsing large tokens can trigger a denial of service │
│                  │                │          │                         │               │ https://avd.aquasec.com/nvd/cve-2023-52425                  │
├──────────────────┼────────────────┤          ├─────────────────────────┼───────────────┼─────────────────────────────────────────────────────────────┤
│ libgssapi-krb5-2 │ CVE-2024-26462 │          │ 1.20.1-2+deb12u2        │               │ krb5: Memory leak at /krb5/src/kdc/ndr.c                    │
│                  │                │          │                         │               │ https://avd.aquasec.com/nvd/cve-2024-26462                  │
├──────────────────┤                │          │                         ├───────────────┤                                                             │
│ libk5crypto3     │                │          │                         │               │                                                             │
│                  │                │          │                         │               │                                                             │
├──────────────────┤                │          │                         ├───────────────┤                                                             │
│ libkrb5-3        │                │          │                         │               │                                                             │
│                  │                │          │                         │               │                                                             │
├──────────────────┤                │          │                         ├───────────────┤                                                             │
│ libkrb5support0  │                │          │                         │               │                                                             │
│                  │                │          │                         │               │                                                             │
├──────────────────┼────────────────┤          ├─────────────────────────┼───────────────┼─────────────────────────────────────────────────────────────┤
│ libldap-2.5-0    │ CVE-2023-2953  │          │ 2.5.13+dfsg-5           │               │ openldap: null pointer dereference in ber_memalloc_x        │
│                  │                │          │                         │               │ function                                                    │
│                  │                │          │                         │               │ https://avd.aquasec.com/nvd/cve-2023-2953                   │
├──────────────────┤                │          │                         ├───────────────┤                                                             │
│ libldap-common   │                │          │                         │               │                                                             │
│                  │                │          │                         │               │                                                             │
├──────────────────┼────────────────┤          ├─────────────────────────┼───────────────┼─────────────────────────────────────────────────────────────┤
│ libxml2          │ CVE-2022-49043 │          │ 2.9.14+dfsg-1.3~deb12u1 │               │ libxml: use-after-free in xmlXIncludeAddNode                │
│                  │                │          │                         │               │ https://avd.aquasec.com/nvd/cve-2022-49043                  │
│                  ├────────────────┤          │                         ├───────────────┼─────────────────────────────────────────────────────────────┤
│                  │ CVE-2024-25062 │          │                         │               │ libxml2: use-after-free in XMLReader                        │
│                  │                │          │                         │               │ https://avd.aquasec.com/nvd/cve-2024-25062                  │
├──────────────────┼────────────────┤          ├─────────────────────────┼───────────────┼─────────────────────────────────────────────────────────────┤
│ perl-base        │ CVE-2023-31484 │          │ 5.36.0-7+deb12u1        │             
sudo docker run --rm -it eremark/booking-website bash
apt update && apt upgrade -y
exit
sudo docker ps
sudo docker stop a14586e8aba4
sudo docker rm a14586e8aba4
apt update && apt upgrade -y
sudo docker run --rm -it --user root eremark/booking-website bash
sudo docker commit $(sudo docker ps -lq) eremark/booking-website
cd /path/to/your/project
pwd
cd /home/ec2-user/booking-website
nano Dockerfile
sudo docker build -t booking-monitoring .
sudo apt update && sudo apt install -y wget
wget https://github.com/aquasecurity/trivy/releases/latest/download/trivy_0.50.1_linux_amd64.tar.gz
tar -xvf trivy_0.50.1_linux_amd64.tar.gz
sudo mv trivy /usr/local/bin/
trivy --version
[ec2-user@ip-172-31-84-4 ~]$ sudo apt update && sudo apt install -y wget
wget https://github.com/aquasecurity/trivy/releases/latest/download/trivy_0.50.1_linux_amd64.tar.gz
tar -xvf trivy_0.50.1_linux_amd64.tar.gz
sudo mv trivy /usr/local/bin/
trivy --version
sudo: apt: command not found
--2025-02-13 17:10:31--  https://github.com/aquasecurity/trivy/releases/latest/download/trivy_0.50.1_linux_amd64.tar.gz
Resolving github.com (github.com)... 140.82.112.3
Connecting to github.com (github.com)|140.82.112.3|:443... connected.
HTTP request sent, awaiting response... 302 Found
Location: https://github.com/aquasecurity/trivy/releases/download/v0.59.1/trivy_0.50.1_linux_amd64.tar.gz [following]
--2025-02-13 17:10:31--  https://github.com/aquasecurity/trivy/releases/download/v0.59.1/trivy_0.50.1_linux_amd64.tar.gz
Reusing existing connection to github.com:443.
HTTP request sent, awaiting response... 404 Not Found
2025-02-13 17:10:31 ERROR 404: Not Found.
tar: trivy_0.50.1_linux_amd64.tar.gz: Cannot open: No such file or directory
tar: Error is not recoverable: exiting now
mv: cannot stat 'trivy': No such file or directory
Version: 0.34.0
Vulnerability DB:
  Version: 2
  UpdatedAt: 2025-02-12 12:17:27.
sudo yum update -y
[ec2-user@ip-172-31-84-4 ~]$ sudo yum update -y
Last metadata expiration check: 1 day, 12:13:15 ago on Wed Feb 12 05:03:03 2025.
================================================================================
WARNING:
  A newer release of "Amazon Linux" is available.
  Available Versions:
  Version 2023.6.20250123:
    Run the following command to upgrade to 2023.6.20250123:
      dnf upgrade --releasever=2023.6.20250123
    Release notes:
     https://docs.aws.amazon.com/linux/al2023/release-notes/relnotes-2023.6.20250123.html
  Version 2023.6.20250128:
    Run the following command to upgrade to 2023.6.20250128:
      dnf upgrade --releasever=2023.6.20250128
    Release notes:
     https://docs.aws.amazon.com/linux/al2023/release-notes/relnotes-2023.6.20250128.html
  Version 2023.6.20250203:
    Run the following command to upgrade to 2023.6.20250203:
      dnf upgrade --releasever=2023.6.20250203
    Release notes:
     https://docs.aws.amazon.com/linux/al2023/release-notes/relnotes-2023.6.20250203.html
=======================================================
sudo yum install -y wget
wget https://github.com/aquasecurity/trivy/releases/latest/download/trivy_0.59.1_Linux-64bit.tar.gz
tar -xvf trivy_0.59.1_Linux-64bit.tar.gz
sudo mv trivy /usr/local/bin/
sudo mv trivy /usr/local/
sudo mv trivy /usr/local/bin/
trivy --version
[ec2-user@ip-172-3
trivy image eremark
[ec2-user@ip-172-31-84-4 ~]$ [ec2-user@ip-172-3
-bash: [ec2-user@ip-172-3: command not found
[ec2-user@ip-172-31-84-4 ~]$ trivy image eremark
2025-02-13T17:20:32Z    INFO    [vulndb] Need to update DB
2025-02-13T17:20:32Z    INFO    [vulndb] Downloading vulnerability DB...
2025-02-13T17:20:32Z    INFO    [vulndb] Downloading artifact...        repo="mirror.gcr.io/aquasec/trivy-db:2"
59.14 MiB / 59.14 MiB [-----------------------------] 100.00% 13.03 MiB p/s 4.8s
2025-02-13T17:20:37Z    INFO    [vulndb] Artifact successfully downloaded      repo="mirror.gcr.io/aquasec/trivy-db:2"
2025-02-13T17:20:37Z    INFO    [vuln] Vulnerability scanning is enabled
2025-02-13T17:20:37Z    INFO    [secret] Secret scanning is enabled
2025-02-13T17:20:37Z    INFO    [secret] If your scanning is slow, please try '--scanners vuln' to disable secret scanning
2025-02-13T17:20:37Z    INFO    [secret] Please see also https://aquasecurity.github.io/trivy/v0.59/docs/scanner/secret#recommendation for faster secret detection
2025-02-13T17:20:38Z    FATAL   Fatal error     image scan error: scan error: unable to initialize a scanner: unable to initialize an image scanner: unable to find the specified image "eremark" in ["docker" "containerd" "podman" "remote"]: 4 errors occurred:
        * docker error: unable to inspect the image (eremark): Error response from daemon: No such image: eremark:latest
        * containerd error: failed to parse image reference: eremark
        * podman error: unable to initialize Podman client: no podman socket found: stat /run/user/1000/podman/podman.sock: no such file or directory
        * remote error: GET https://index.docker.io/v2/library/eremark/manifests/latest: UNAUTHORIZED: authentication required; [map[
docker images
trivy image eremark/booking-website
ls -l .github/workflows/
cat .github/workflows/deploy.yml
sudo docker run -d   --name=cadvisor   --privileged   --publish=8080:8080   --volume=/var/run/docker.sock:/var/run/docker.sock   --volume=/sys:/sys   --volume=/cgroup:/cgroup   google/cadvisor:latest
sudo docker ps
sudo docker logs cadvisor_new
sudo docker ps -a
[ec2-user@ip-172-31-84-4 ~]$ sudo docker ps -a
CONTAINER ID   IMAGE                            COMMAND                  CREATED          STATUS                            PORTS                               NAMES
8c8791675069   google/cadvisor:latest           "/usr/bin/cadvisor -…"   14 minutes ago   Exited (255) 14 minutes ago                                           cadvisor
30235e033c4b   google/cadvisor:latest           "/usr/bin/cadvisor -…"   26 hours ago     Restarting (255) 15 seconds ago                                       cadvisor_new
55ee02a65598   d46d1bf01c58                     "httpd-foreground"       2 days ago       Up 27 hours                       0.0.0.0:80->80/tcp, :::80->80/tcp   booking-project-web-1
b9621b8c795d   eremark/booking-project:latest   "httpd-foreground"       6 days ago       Exited (0) 27 hours ago                                               booking-container
sudo docker logs cadvisor
sudo docker run -d   --name=cadvisor_test   --privileged   --publish=8080:8080   --volume=/var/run/docker.sock:/var/run/docker.sock   --volume=/sys:/sys   --volume=/cgroup:/cgroup   google/cadvisor:latest
[ec2-user@ip-172-31-84-4 ~]$ sudo docker run -d   --name=cadvisor_test   --privileged   --publish=8080:8080   --volume=/var/run/docker.sock:/var/run/docker.sock   --volume=/sys:/sys   --volume=/cgroup:/cgroup   google/cadvisor:latest
9e8adb7fc00f92ae96f239b958cc525f940f0b45ff5bc62df39f809e854e4f3a
sudo docker logs cadvisor_test
[ec2-user@ip-172-31-84-4 ~]$ sudo docker logs cadvisor_test
F0213 17:58:29.145338       1 cadvisor.go:146] Failed to create a Container Manager: mountpoint for cpu not found
sudo systemctl restart docker
sudo docker run -d   --name=prometheus   --publish=9090:9090   --volume=/etc/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml   prom/prometheus
[ec2-user@ip-172-31-84-4 ~]$ sudo docker run -d   --name=prometheus   --publish=9090:9090   --volume=/etc/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml   prom/prometheus
Unable to find image 'prom/prometheus:latest' locally
latest: Pulling from prom/prometheus
9fa9226be034: Pull complete
1617e25568b2: Pull complete
5223fd66c357: Pull complete
935b618cedfb: Pull complete
343344cc83ef: Pull complete
c5d55cdd4901: Pull complete
bc4feeb9f815: Pull complete
e4517b9a2fa7: Pull complete
8faccf8621bd: Pull complete
21fef47de6b8: Pull complete
Digest: sha256:6559acbd5d770b15bb3c954629ce190ac3cbbdb2b7f1c30f0385c4e05104e218
Status: Downloaded newer image for prom/prometheus:latest
c0d49c9dc35cd985ad30d9bde5757c8e07f40f70cb54ed863cd1eab30b2436ef
docker: Error response from daemon: failed to create task for container: failed to create shim task: OCI runtime create failed: runc create failed: unable to start container process: error during container init: error mounting "/etc/prometheus/prometheus.yml" to rootfs at "/etc/prometheus/prometheus.yml": create mount destination for /etc/prometheus/prometheus.yml mount: cannot mkdir in /var/lib/docker/overlay2/fe228dbe3eb1be3373b5058dc0eac6eec557591ba960c8a07113517b01ad9284/merged/etc/prometheus/prometheus.yml: not a directory: unknown: Are you trying to mount a directory onto a file (or vice-versa)? Check if the specified host path exists and is the expected type.
[ec2-user@ip-172-31-84-4 ~]$ sudo docker run -d   --name=prometheus   --publish=9090:9090   --volume=/etc/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml   prom/prometheus
Unable to find image 'prom/prometheus:latest' locally
latest: Pulling from prom/prometheus
9fa9226be034: Pull complete
1617e25568b2: Pull complete
5223fd66c357: Pull complete
935b618cedfb: Pull complete
343344cc83ef: Pull complete
c5d55cdd4901: Pull complete
bc4feeb9f815: Pull complete
e4517b9a2fa7: Pull complete
8faccf8621bd: Pull complete
21fef47de6b8: Pull complete
Digest: sha256:6559acbd5d770b15bb3c954629ce190ac3cbbdb2b7f1c30f0385c4e05104e218
Status: Downloaded newer image for prom/prometheus:latest
c0d49c9dc35cd985ad30d9bde5757c8e07f40f70cb54ed863cd1eab30b2436ef
docker: Error response from daemon: failed to create task for container: failed to create shim task: OCI runtime create failed: runc create failed: unable to start container process: error during container init: error mounting "/etc/prometheus/prometheus.yml" to rootfs at "/etc/prometheus/prometheus.yml": create mount destination for /etc/prometheus/prometheus.yml mount: cannot mkdir in /var/lib/docker/overlay2/fe228dbe3eb1be3373b5058dc0eac6eec557591ba960c8a07113517b01ad9284/merged/etc/prometheus/prometheus.yml: not a directory: unknown: Are you trying to mount a directory onto a file (or vice-versa)? Check if the specified host path exists and is the expected type.
sudo mkdir -p /etc/prometheus
sudo cp prometheus.yml /etc/prometheus/prometheus.yml  # Если конфигурационный файл еще не был создан
sudo docker run -d   --name=prometheus   --publish=9090:9090   --volume=/etc/prometheus:/etc/prometheus   prom/prometheus
sudo mkdir -p /etc/prometheus
sudo cp /path/to/your/prometheus.yml /etc/prometheus/prometheus.yml
[ec2-user@ip-172-31-84-4 ~]$ sudo cp /path/to/your/prometheus.yml /etc/prometheus/prometheus.yml
cp: cannot stat '/path/to/your/prometheus.yml': No such file or directory
[ec2-user@ip-172-31-84-4 ~]$ sudo cp /path/to/your/prometheus.yml /etc/prometheus/prometheus.yml
cp: cannot stat '/path/to/your/prometheus.yml': No such file or directory
sudo nano /etc/prometheus/prometheus.yml
sudo docker run -d   --name=prometheus   --publish=9090:9090   --volume=/etc/prometheus:/etc/prometheus   prom/prometheus
[ec2-user@ip-172-31-84-4 ~]$ sudo docker run -d   --name=prometheus   --publish=9090:9090   --volume=/etc/prometheus:/etc/prometheus   prom/prometheus
docker: Error response from daemon: Conflict. The container name "/prometheus" is already in use by container "c0d49c9dc35cd985ad30d9bde5757c8e07f40f70cb54ed863cd1eab30b2436ef". You have to remove (or rename) that container to be able to reuse that name.
See 'docker run --help'.
sudo docker rm -f prometheus
sudo docker run -d   --name=prometheus   --publish=9090:9090   --volume=/etc/prometheus:/etc/prometheus   prom/prometheus
sudo docker run -d   --name=prometheus   --publish=9090:9090   --volume=/etc/prometheus:/etc/prometheus   prom/prometheus
sudo docker logs cadvisor_new
openssl x509 -in /etc/letsencrypt/live/boking.pp.ua/fullchain.pem -text -noout
ls -l /etc/letsencrypt/live/boking.pp.ua/
sudo openssl x509 -in /etc/letsencrypt/live/boking.pp.ua/fullchain.pem -text -noout
сдуфк 
clear
openssl s_client -connect boking.pp.ua:443 -showcerts
openssl s_client -connect boking.pp.ua:443 -servername boking.pp.ua </dev/null | openssl x509 -noout -text
echo | openssl s_client -connect boking.pp.ua:443 2>/dev/null | openssl x509 -noout -dates
clear 
sudo yum install -y certbot
sudo systemctl stop httpd
sudo certbot certonly --standalone -d boking.pp.ua
[ec2-user@ip-172-31-84-4 ~]$ sudo certbot certonly --standalone -d boking.pp.ua
Saving debug log to /var/log/letsencrypt/letsencrypt.log
Certificate not yet due for renewal
You have an existing certificate that has exactly the same domains or certificate name you requested and isn't close to expiry.
(ref: /etc/letsencrypt/renewal/boking.pp.ua.conf)

What would you like to do?
- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
1: Keep the existing certificate for now
2: Renew & replace the certificate (may be subject to CA rate limits)
- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
Select the appropriate number [1-2] then [enter] (press 'c' to cancel): 2
Renewing an existing certificate for boking.pp.ua

Successfully received certificate.
Certificate is saved at: /etc/letsencrypt/live/boking.pp.ua/fullchain.pem
Key is saved at:         /etc/letsencrypt/live/boking.pp.ua/privkey.pem
This certificate expires on 2025-05-16.
These files will be updated when the certificate renews.
Certbot has set up a scheduled task to automatically renew this certificate in the background.

- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
If you like Certbot, please consider supporting our work by:
 * Donating to ISRG / Let's Encrypt:   https://letsencrypt.org/donate
 * Donating to EFF:                    https://eff.org/donate-le
- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
[ec2-user@ip-172-31-84-4 ~]$
clear
sudo systemctl status apache2
sudo systemctl status httpd
sudo yum list installed | grep httpd
sudo yum install httpd
ps aux | grep httpd
[ec2-user@ip-172-31-84-4 ~]$ ps aux | grep httpd
ec2-user 2430215  0.0  0.2 222316  2076 pts/0    S+   19:25   0:00 grep --color=auto httpd
sudo systemctl start httpd
sudo systemctl status httpd
sudo systemctl enable httpd
ps aux | grep httpd
[ec2-user@ip-172-31-84-4 ~]$ ps aux | grep httpd
root     2430226  0.0  1.5  19416 14932 ?        Ss   19:25   0:00 /usr/sbin/httpd -DFOREGROUND
apache   2430285  0.0  0.5  19072  5144 ?        S    19:25   0:00 /usr/sbin/httpd -DFOREGROUND
apache   2430286  0.0  0.8 1087040 8512 ?        Sl   19:25   0:00
clear
sudo netstat -tuln | grep 443
[ec2-user@ip-172-31-84-4 ~]$ sudo netstat -tuln | grep 443
tcp        0      0 127.0.0.1:43443         0.0.0.0:*               LISTEN
tcp6       0      0 :::443                  :::*                    LISTEN
[ec2-user@ip-172-31-84-4 ~]$
sudo nano /etc/httpd/conf.d/ssl.conf
sudo systemctl restart httpd
sudo docker ps
[ec2-user@ip-172-31-84-4 ~]$ sudo docker ps
CONTAINER ID   IMAGE                    COMMAND                  CREATED      ST                                                                                                                                                             ATUS                            PORTS     NAMES
30235e033c4b   google/cadvisor:latest   "/usr/bin/cadvisor -…"   3 days ago   Re                                                                                                                                                             starting (255) 59 seconds ago             cadvisor_new
[ec2-user@ip-172-31-
sudo docker ps -a
[ec2-user@ip-172-31-84-4 ~]$ sudo docker ps -a
CONTAINER ID   IMAGE                            COMMAND                  CREATED                                                                                                                                                                   STATUS                           PORTS     NAMES
e5a39eddb7ab   prom/prometheus                  "/bin/prometheus --c…"   2 days                                                                                                                                                              ago   Exited (2) 2 days ago                      prometheus
9e8adb7fc00f   google/cadvisor:latest           "/usr/bin/cadvisor -…"   2 days                                                                                                                                                              ago   Exited (255) 2 days ago                    cadvisor_test
8c8791675069   google/cadvisor:latest           "/usr/bin/cadvisor -…"   2 days                                                                                                                                                              ago   Exited (255) 2 days ago                    cadvisor
30235e033c4b   google/cadvisor:latest           "/usr/bin/cadvisor -…"   3 days                                                                                                                                                              ago   Restarting (255) 8 seconds ago             cadvisor_new
55ee02a65598   d46d1bf01c58                     "httpd-foreground"       4 days                                                                                                                                                              ago   Exited (0) 2 days ago                      booking-project-web-1
b9621b8c795d   eremark/booking-project:latest   "httpd-foreground"       8 days                                                                                                                                         
sudo docker start booking-project-web-1
[ec2-user@ip-172-31-84-4 ~]$ sudo docker start booking-project-web-1
Error response from daemon: driver failed programming external connectivity on endpoint booking-project-web-1 (32bc83b8b7d1881e6511235d409f65cf282dd682b65d04431f415f14a3365824): Error starting userland proxy: listen tcp4 0.0.0.0:80: bind: address already in use
Error: failed to start containers: booking-project-web-1
[ec2-user@ip-172-31-84-4 ~]$
sudo docker start booking-container
sudo docker ps
docker images | grep booking-project
[ec2-user@ip-172-31-84-4 ~]$ docker images | grep booking-project
eremark/booking-project   latest    d46d1bf01c58   3 weeks ago   148MB
docker ps | grep booking-project
docker ps
curl -I http://localhost
ls -la
git status
ls -la
git log --oneline --graph --decorate --all
cat index.html
sudo docker ps
ping -c 4 18.212.28.144
ping -c 4 booking.pp.ua
clear 
docker login
docker search eremark/booking-project
docker pull eremark/booking-project:latest
curl --header "PRIVATE-TOKEN: YOUR_ACCESS_TOKEN" "https://gitlab.com/api/v4/projects/YOUR_PROJECT_ID/pipelines"
sudo docker pull eremark/booking-project:latest
sudo docker stop booking-project-web-1
sudo docker rm booking-project-web-1
sudo docker run -d -p 80:80 -p 443:443 --name booking-project-web-1 eremark/booking-project:latest
curl -I http://booking.pp.ua
curl -I https://booking.pp.ua
sudo docker logs booking-project-web-1 --tail 50
[ec2-user@ip-172-31-84-4 ~]$ docker login
docker search eremark/booking-project
docker pull eremark/booking-project:latest
Authenticating with existing credentials...
WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.
Configure a credential helper to remove this warning. See
https://docs.docker.com/engine/reference/commandline/login/#credentials-store
Login Succeeded
NAME                                                           DESCRIPTION                                     STARS     OFFICIAL
eremark/booking-project                                        Второй репозиторий                              0
zooproject/zoo-project                                         ZOO-Project official image                      1
rootproject/root                                               ROOT Data Analysis Framework Official Docker…   24
ltbproject/self-service-password                               LDAP Tool Box Self Service Password             16
edirom/project.zenmem.de                                                                                       0
opensearchproject/opensearch                                   The Official Docker Image of OpenSearch (htt…   159
projectcontour/contour                                         Contour is a Kubernetes ingress controller u…   0
cortexproject/cortex                                           Cortex: horizontally scalable, highly availa…   5
cincproject/cinc                                               Community rebuild of Chef Infra Client          0
opensearchproject/opensearch-dashboards                        The Official Docker Image of OpenSearch Dash…   42
rancher/helm-project-operator                                                                                  0
cortexproject/test-exporter                                                                                    0
cincproject/auditor                                            Cinc community rebuild of Chef InSpec           1
opensearchproject/logstash-oss-with-opensearch-output-plugin   The Official Docker Image of Logstash with O…   21
freelawproject/case-law-access-project-server                                                                  0
cincproject/workstation                                        Cinc community rebuild of Chef Workstation      0
protegeproject/webprotege                                      WebProtégé is a free, open source collaborat…   5
opensearchproject/data-prepper                                 The Official Docker Image of OpenSearch Data…   14
corpusops/project                                              https://github.com/corpusops/docker-project/    0
zooproject/websocketd                                                                                          0
linuxserver/projectsend                                        A ProjectSend container, brought to you by L…   84
projectcontour/contour-operator                                Experimental operator for deploying Contour     0
freelawproject/case-law-access-project-client                                                                  0
opensearchproject/opensearch-operator                                                                          0
cincproject/omnibus-debian                                     Debian Omnibus builder                          0
latest: Pulling from eremark/booking-project
Digest: sha256:1806fdc54e9d93c5ce8bdf5a3ba53829164c4ebae71ce083c0619f7ea10fd6ad
Status: Image is up to date for eremark/booking-project:latest
docker.io/eremark/booking-project:latest
[ec2-user@ip-172-31-84-4 ~]$ curl --header "PRIVATE-TOKEN: YOUR_ACCESS_TOKEN" "https://gitlab.com/api/v4/projects/YOUR_PROJECT_ID/pipelines"
{"message":"401 Unauthorized"}[ec2-user@ip-172-31-84-4 ~]$ sudo docker pull eremark/booking-project:latest   sudo docker pull eremark/booking-project:latest
sudo docker stop booking-project-web-1
sudo docker rm booking-project-web-1
sudo docker run -d -p 80:80 -p 443:443 --name booking-project-web-1 eremark/booking-project:latest
latest: Pulling from eremark/booking-project
Digest: sha256:1806fdc54e9d93c5ce8bdf5a3ba53829164c4ebae71ce083c0619f7ea10fd6ad
Status: Image is up to date for eremark/booking-project:latest
docker.io/eremark/booking-project:latest
booking-project-web-1
d3b11162d411af99c5b4f2df476d523fa8281da34c5e012a7bef50ca33e1fe42
docker: Error response from daemon: driver failed programming external connectivity on endpoint booking-project-web-1 (055596e3fe91187612985ef6d1100810ea1f13635302ab3101e2c183f2361a98): Error starting userland proxy: listen tcp4 0.0.0.0:443: bind: address already in use.
[ec2-user@ip-172-31-84-4 ~]$ curl -I http://booking.pp.ua
curl -I https://booking.pp.ua
HTTP/1.1 301 Moved Permanently
Date: Sun, 16 Feb 2025 13:21:28 GMT
Server: Apache/2.4.52 (Ubuntu)
Location: https://booking.pp.ua/
Content-Type: text/html; charset=iso-8859-1
curl: (60) SSL: no alternative certificate subject name matches target host name 'booking.pp.ua'
More details here: https://curl.se/docs/sslcerts.html
curl failed to verify the legitimacy of the server and therefore could not
establish a secure connection to it. To learn more about this situation and
how to fix it, please visit the web page mentioned above.
[ec2-user@ip-172-31-84-4 ~]$ sudo docker logs booking-project-web-1 --tail 50
[ec2-user@ip-172-31-84-4 ~]$
docker images | grep booking-project
docker search eremark/booking-project
docker ps -a | grep booking-project
curl --header "PRIVATE-TOKEN: YOUR_ACCESS_TOKEN" "https://gitlab.com/api/v4/projects/YOUR_PROJECT_ID/pipelines"
docker ps | grep booking-project
curl -I http://booking.pp.ua
curl -I https://booking.pp.ua
sudo yum install -y wget
wget https://github.com/aquasecurity/trivy/releases/latest/download/trivy_Linux-64bit.tar.gz
tar -xvf trivy_Linux-64bit.tar.gz
sudo mv trivy /usr/local/bin/
trivy image eremark/booking-project:latest
2.	curl --header "PRIVATE-TOKEN: YOUR_ACCESS_TOKEN" "https://gitlab.com/api/v4/projects/YOUR_PROJECT_ID/pipelines"
docker ps | grep booking-project
clear
sudo apt install python3-certbot-nginx
certbot --version
sudo certbot --nginx -d web.booking.pp.ua
sudo nginx -t
sudo systemctl restart nginx
sudo netstat -tulnp | grep LISTEN
sudo yum install -y epel-release
sudo yum install -y certbot python3-certbot-apache
Last metadata expiration check: 1
sudo certbot --apache
sudo certbot --apache -d boking.pp.ua
[ec2-user@ip-172-31-84-4 ~]$ sudo certbot --apache -d boking.pp.ua
Saving debug log to /var/log/letsencrypt/letsencrypt.log
Certificate not yet due for renewal
You have an existing certificate that has exactly the same domains or certificate name you requested and isn't close to expiry.
(ref: /etc/letsencrypt/renewal/boking.pp.ua.conf)

What would you like to do?
- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
1: Attempt to reinstall this existing certificate
2: Renew & replace the certificate (may be subject to CA rate limits)
- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
Select the appropriate number [1-2] then [enter] (press 'c' to cancel): 2
Renewing an existing certificate for boking.pp.ua

Successfully received certificate.
Certificate is saved at: /etc/letsencrypt/live/boking.pp.ua/fullchain.pem
Key is saved at:         /etc/letsencrypt/live/boking.pp.ua/privkey.pem
This certificate expires on 2025-05-18.
These files will be updated when the certificate renews.
Certbot has set up a scheduled task to automatically renew this certificate in the background.

Deploying certificate
Successfully deployed certificate for boking.pp.ua to /etc/httpd/conf.d/vhost-le-ssl.conf
Your existing certificate has been successfully renewed, and the new certificate has been installed.

- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
If you like Certbot, please consider supporting our work by:
 * Donating to ISRG / Let's Encrypt:   https://letsencrypt.org/donate
 * Donating to EFF:                    https://eff.org/donate-le
sudo systemctl restart httpd
sudo openssl req -x509 -nodes -days 365 -newkey rsa:2048   -keyout /etc/ssl/private/ip_address.key   -out /etc/ssl/certs/ip_address.crt
[ec2-user@ip-172-31-84-4 ~]$ sudo openssl req -x509 -nodes -days 365 -newkey rsa:2048   -keyout /etc/ssl/private/ip_address.key   -out /etc/ssl/certs/ip_address.crt
...+...........+.+........+.+.....................+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++*.+.+.....+.........+....+..+.......+......+.........+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++*..+.+...+......+...........+.......+.....+..........+..+..................+...+....+.........+..+...+..........+...........+...+.+.....+.........+.............+..+...+....+......+.....+...+....+......+..+....+.....+...+...+...................+...+..+.........+.+......+..+...+.......+..+......+...+.+...+..+...............+...+............+......+.............+.....+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
.+...+..+.......+...+..+..................+...+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++*......................+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++*..........+....+......+........+.......+.....+...............+.+..+...+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
req: Can't open "/etc/ssl/private/ip_add

фыс34
sudo mkdir -p /etc/ssl/private
sudo mkdir -p /etc/ssl/certs
sudo chmod 700 /etc/ssl/private
sudo openssl req -x509 -nodes -days 365 -newkey rsa:2048   -keyout /etc/ssl/private/ip_address.key   -out /etc/ssl/certs/ip_address.crt
sudo nano /etc/httpd/conf.d/ip-ssl.conf
sudo apachectl configtest
sudo systemctl restart httpd
curl -k https://18.212.28.144
sudo netstat -tulnp | grep 443
sudo apachectl -t -D DUMP_VHOSTS
sudo cp /etc/ssl/certs/ip_address.crt /home/ec2-user/
ls -l /etc/ssl/certs/ip_address.crt
ls -l /etc/ssl/private/ip_address.key
[ec2-user@ip-172-31-84-4 ~]$ ls -l /etc/ssl/certs/ip_address.crt
ls -l /etc/ssl/private/ip_address.key
-rw-r--r--. 1 root root 1440 Feb 17 14:12 /etc/ssl/certs/ip_address.crt
ls: cannot access '/etc/ssl/private/ip_address.key': Permission denied
[ec2-user@ip-172-31-84-4 ~]$
sudo ls -l /etc/ssl/private/ip_address.key
sudo chmod 600 /etc/ssl/private/ip_address.key
ls -l /etc/ssl/certs/ip_address.crt
ls -l /etc/ssl/private/ip_address.key
sudo systemctl restart httpd
sudo nano /etc/httpd/conf.d/ip-ssl.conf
sudo nano /etc/httpd/conf/httpd.conf
sudo apachectl -M | grep ssl
[ec2-user@ip-172-31-84-4 ~]$ sudo apachectl -M | grep ssl
apachectl: The "-M" option is not supported.
sudo httpd -M | grep ssl
[ec2-user@ip-172-31-84-4 ~]$ sudo httpd -M | grep ssl
 ssl_module (shared)
sudo nano /etc/httpd/conf/httpd.conf
ls -l /etc/ssl/certs/ip_address.crt
ls -l /etc/ssl/private/ip_address.key
sudo systemctl restart httpd
sudo systemctl status httpd
sudo netstat -tulnp | grep 443
sudo netstat -tulnp | grep 80
sudo tail -f /var/log/httpd/error_log
sudo rm /etc/ssl/certs/ip_address.crt /etc/ssl/private/ip_address.key
sudo openssl req -x509 -nodes -days 365 -newkey rsa:2048     -keyout /etc/ssl/private/ip_address.key     -out /etc/ssl/certs/ip_address.crt     -subj "/C=US/ST=NewYork/L=NYC/O=MyCompany/CN=18.212.28.144"
sudo systemctl restart httpd
curl -v https://18.212.28.144 --insecure
[ec2-user@ip-172-31-84-4 ~]$ curl -v https://18.212.28.144 --insecure
*   Trying 18.212.28.144:443...
* Connected to 18.212.28.144 (18.212.28.144) port 443
* ALPN: curl offers h2,http/1.1
* TLSv1.3 (OUT), TLS handshake, Client hello (1):
* TLSv1.3 (IN), TLS handshake, Server hello (2):
* TLSv1.3 (IN), TLS handshake, Encrypted Extensions (8):
* TLSv1.3 (IN), TLS handshake, Certificate (11):
* TLSv1.3 (IN), TLS handshake, CERT verify (15):
* TLSv1.3 (IN), TLS handshake, Finished (20):
* TLSv1.3 (OUT), TLS change cipher, Change cipher spec (1):
* TLSv1.3 (OUT), TLS handshake, Finished (20):
* SSL connection using TLSv1.3 / TLS_AES_256_GCM_SHA384 / X25519 / RSASSA-PSS
* ALPN: server accepted http/1.1
* Server certificate:
*  subject: C=US; ST=NewYork; L=NYC; O=MyCompany; CN=18.212.28.144
*  start date: Feb 17 18:33:01 2025 GMT
*  expire date: Feb 17 18:33:01 2026 GMT
*  issuer: C=US; ST=NewYork; L=NYC; O=MyCompany; CN=18.212.28.144
*  SSL certificate verify result: self-signed certificate (18), continuing anyway.
*   Certificate level 0: Public key type RSA (2048/112 Bits/secBits), signed using sha256WithRSAEncryption
* using HTTP/1.x
> GET / HTTP/1.1
> Host: 18.212.28.144
> User-Agent: curl/8.5.0
> Accept: */*
>
* TLSv1.3 (IN), TLS handshake, Newsession Ticket (4):
* old SSL session ID is stale, removing
< HTTP/1.1 200 OK
< Date: Mon, 17 Feb 2025 18:33:25 GMT
< Server: Apache/2.4.62 (Amazon Linux) OpenSSL/3.0.8
< Last-Modified: Fri, 24 Jan 2025 10:48:53 GMT
< ETag: "2a-62c7178fe28dd"
< Accept-Ranges: bytes
< Conten
sudo nano /etc/httpd/conf.d/ip-ssl.conf
sudo systemctl restart httpd
curl -v http://18.212.28.144
[ec2-user@ip-172-31-84-4 ~]$ curl -v http://18.212.28.144
*   Trying 18.212.28.144:80...
* Connected to 18.212.28.144 (18.212.28.144) port 80
> GET / HTTP/1.1
> Host: 18.212.28.144
> User-Agent: curl/8.5.0
> Accept: */*
>
< HTTP/1.1 301 Moved Permanently
< Date: Mon, 17 Feb 2025 18:34:38 GMT
< Server: Apache/2.4.62 (Amazon Linux) OpenSSL/3.0.8
< Location: https://18.212.28.144/
< Content-Length: 230
< Content-Type: text/html; charset=iso-8859-1
<
<html><head>
<title>301 Moved Permanently</title>
</head><body>
<h1>Moved Permanently</h1>
<p>The document has moved <a href="https://18.212.28.144/">here</a>.</p>
</body></html>
* Connection #0 to host 18.212.28.144 left intact
когда открываю в гугле все равно не защищено 
sudo yum install -y epel-release
sudo yum install -y certbot python3-certbot-apache
sudo certbot --apache
sudo certbot certificates
[ec2-user@ip-172-31-84-4 ~]$ sudo certbot certificates
Saving debug log to /var/log/letsencrypt/letsencrypt.log
- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
Found the following certs:
  Certificate Name: boking.pp.ua
    Serial Number: 4088d0c312bd4af4a00fd2c71878b178951
    Key Type: ECDSA
    Domains: boking.pp.ua
    Expiry Date: 2025-05-18 12:47:29+00:00 (VALID: 89 days)
    Certificate Path: /etc/letsencrypt/live/boking.pp.ua/fullchain.pem
    Private Key Path: /etc/letsencrypt/live/boking.pp.ua/privkey.pem
sudo nano /etc/httpd/conf.d/ssl.conf
sudo systemctl restart httpd
curl -v https://boking.pp.ua
sudo ls -l /etc/ssl/private/ip_address.key
sudo nano /etc/httpd/conf.d/ip-ssl.conf
sudo tail -f /var/log/httpd/ip_ssl_error.log
sudo journalctl -xe | grep httpd
sudo netstat -tulnp | grep 443
sudo apachectl -M | grep ssl
[ec2-user@ip-172-31-84-4 ~]$ sudo apachectl -M | grep ssl
apachectl: The "-M" option is not supported.
sudo httpd -M | grep ssl
sudo nano /etc/httpd/conf.d/ssl.conf
sudo systemctl restart httpd
sudo nano /etc/httpd/conf.d/ip-ssl.conf
sudo systemctl restart httpd
sudo netstat -tulnp | grep 443
SSLCertificateFile /etc/ssl/certs/ip_address.crt
SSLCertificateKeyFile /etc/ssl/private/ip_address.key
sudo tail -n 100 /var/log/httpd/error_log
openssl s_client -connect 18.212.28.144:443
[ec2-user@ip-172-31-84-4 ~]$ openssl s_client -connect 18.212.28.144:443
800B674C737F0000:error:8000006F:system lib
curl -I http://18.212.28.144
sudo netstat -tulnp | grep 443
sudo firewall-cmd --permanent --zone=public --add-port=443/tcp
sudo firewall-cmd --permanent --zone=public --add-port=80/tcp
sudo firewall-cmd --reload
sudo nano /etc/httpd/conf.d/redirect-ip.conf
sudo systemctl restart httpd
sudo netstat -tulnp | grep httpd
sudo nano /etc/httpd/conf/httpd.conf
sudo systemctl restart httpd
sudo systemctl status httpd.service
sudo firewall-cmd --list-all
sudo firewall-cmd --add-service=http --permanent
sudo firewall-cmd --add-service=https --permanent
sudo firewall-cmd --reload
clear
sudo iptables -L -n -v
   
 
sudo systemctl restart httpd
j
sudo journalctl -xeu httpd.service | tail -20
[ec2-user@ip-172-31-84-4 ~]$ sudo journalctl -xeu httpd.service | tail -20
░░ Defined-By: systemd
░░ Support: https://lists.freedesktop.org/mailman/listinfo/systemd-devel
░░
░░ An ExecStart= process belonging to unit httpd.service has exited.
░░
░░ The process' exit code is 'exited' and its exit status is 1.
Feb 19 16:37:12 ip-172-31-84-4.ec2.internal systemd[1]: httpd.service: Failed with result 'exit-code'.
░░ Subject: Unit failed
░░ Defined-By: systemd
░░ Support: https://lists.freedesktop.org/mailman/listinfo/systemd-devel
░░
░░ The unit httpd.service has entered the 'failed' state with result 'exit-code'.
Feb 19 16:37:12 ip-172-31-84-4.ec2.internal systemd[1]: Failed to start httpd.service - The Apache HTTP Server.
░░ Subject: A start job for unit httpd.service has failed
░░ Defined-By: systemd
░░ Support: https://lists.freedesktop.org/mailman/listinfo/systemd-devel
░░
░░ A start job for unit httpd.service has finished with a failure.
░░
░░ The job identifier is 2246185 and the job result is failed.

exit

